{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd433cb6-e48a-45ed-98b2-6fd9a560f2da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "import joblib\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler, NearMiss\n",
    "from sklearn.base import clone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70807e9c-f86e-4cdf-9078-38d981c25bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data = pd.read_csv('../data/cleaned/combined_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b8bd51-d020-462b-b1bb-6f6a63859c84",
   "metadata": {},
   "source": [
    "### Model with original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8884ddf1-d3eb-436e-8d0a-91c37e3c0ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the KNN model from the file\n",
    "knn_model = joblib.load('../src/knn_model.pkl')\n",
    "\n",
    "# Load the Logistic Regression model from the file\n",
    "logreg_model = joblib.load('../src/logreg_model.pkl')\n",
    "\n",
    "# Load the Decision Tree model from the file\n",
    "dt_model = joblib.load('../src/dt_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9cf6b3fb-449f-40b3-aae8-abcede1b41d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8309352517985612\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          No       0.84      0.99      0.90       226\n",
      "         Yes       0.73      0.15      0.25        52\n",
      "\n",
      "    accuracy                           0.83       278\n",
      "   macro avg       0.78      0.57      0.58       278\n",
      "weighted avg       0.82      0.83      0.78       278\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " [[223   3]\n",
      " [ 44   8]]\n",
      "Cohen's Kappa for Stacking Model: 0.20183262064752594\n"
     ]
    }
   ],
   "source": [
    "X1 = combined_data.drop('attrition', axis=1)\n",
    "y1= combined_data['attrition']\n",
    "\n",
    "# Identify categorical columns to be encoded\n",
    "columns_to_encode = ['business_travel', 'department', 'education_field', 'gender', 'job_role', 'marital_status', 'over_time']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(X1, y1, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the transformer for categorical columns (OneHotEncoder)\n",
    "categorical_transformer = OneHotEncoder(drop='first')\n",
    "\n",
    "# Combine transformers using ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', categorical_transformer, columns_to_encode),\n",
    "    ])\n",
    "# Apply one-hot encoding to training and test sets\n",
    "X_train_encoded1 = preprocessor.fit_transform(X_train1)\n",
    "X_test_encoded1 = preprocessor.transform(X_test1)\n",
    "estimators = [\n",
    "    ('knn', knn_model),\n",
    "    ('logreg', logreg_model),\n",
    "    ('dt', dt_model)\n",
    "]\n",
    "\n",
    "# Define the meta-model (you can choose any classifier as a meta-model)\n",
    "meta_model = LogisticRegression(random_state=42)\n",
    "\n",
    "# Create the stacking model\n",
    "stacking_model_1 = StackingClassifier(estimators=estimators, final_estimator=meta_model)\n",
    "\n",
    "# Fit the stacking model\n",
    "stacking_model_1.fit(X_train_encoded1, y_train1)\n",
    "\n",
    "# Predictions on the test set\n",
    "y_pred_stacking1 = stacking_model_1.predict(X_test_encoded1)\n",
    "\n",
    "# Evaluate the performance of the stacking model\n",
    "print(\"Accuracy:\", accuracy_score(y_test1, y_pred_stacking1))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test1, y_pred_stacking1))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test1, y_pred_stacking1))\n",
    "kappa_stacking1 = cohen_kappa_score(y_test1, y_pred_stacking1)\n",
    "print(\"Cohen's Kappa for Stacking Model:\", kappa_stacking1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd3eee9-0b4a-4b00-8689-5295b4e98885",
   "metadata": {},
   "source": [
    "### Model after balancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b689468-164f-4e34-b71d-e07fbc8af447",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Performance after SMOTE:\n",
      "Accuracy (SMOTE): 0.7589928057553957\n",
      "Classification Report (SMOTE):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          No       0.87      0.83      0.85       226\n",
      "         Yes       0.38      0.46      0.42        52\n",
      "\n",
      "    accuracy                           0.76       278\n",
      "   macro avg       0.63      0.64      0.63       278\n",
      "weighted avg       0.78      0.76      0.77       278\n",
      "\n",
      "Confusion Matrix (SMOTE):\n",
      " [[187  39]\n",
      " [ 28  24]]\n",
      "Cohen's Kappa (SMOTE): 0.2672122118183964\n",
      "\n",
      "Performance after RandomUnderSampler:\n",
      "Accuracy (RandomUnderSampler): 0.7122302158273381\n",
      "Classification Report (RandomUnderSampler):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          No       0.89      0.74      0.81       226\n",
      "         Yes       0.34      0.60      0.44        52\n",
      "\n",
      "    accuracy                           0.71       278\n",
      "   macro avg       0.62      0.67      0.62       278\n",
      "weighted avg       0.79      0.71      0.74       278\n",
      "\n",
      "Confusion Matrix (RandomUnderSampler):\n",
      " [[167  59]\n",
      " [ 21  31]]\n",
      "Cohen's Kappa (RandomUnderSampler): 0.2615221144906362\n",
      "\n",
      "Performance after NearMiss:\n",
      "Accuracy (NearMiss): 0.4856115107913669\n",
      "Classification Report (NearMiss):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          No       0.84      0.45      0.59       226\n",
      "         Yes       0.21      0.63      0.32        52\n",
      "\n",
      "    accuracy                           0.49       278\n",
      "   macro avg       0.53      0.54      0.45       278\n",
      "weighted avg       0.72      0.49      0.54       278\n",
      "\n",
      "Confusion Matrix (NearMiss):\n",
      " [[102 124]\n",
      " [ 19  33]]\n",
      "Cohen's Kappa (NearMiss): 0.04835543639584439\n"
     ]
    }
   ],
   "source": [
    "# Separate features (X) and target variable (y)\n",
    "X = combined_data.drop('attrition', axis=1)\n",
    "y = combined_data['attrition']\n",
    "\n",
    "# Identify categorical columns to be encoded\n",
    "columns_to_encode = ['business_travel', 'department', 'education_field', 'gender', 'job_role', 'marital_status', 'over_time']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the transformer for categorical columns (OneHotEncoder)\n",
    "categorical_transformer = OneHotEncoder(drop='first')\n",
    "\n",
    "# Combine transformers using ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', categorical_transformer, columns_to_encode)\n",
    "    ])\n",
    "\n",
    "# Apply one-hot encoding to training and test sets\n",
    "X_train_encoded = preprocessor.fit_transform(X_train)\n",
    "X_test_encoded = preprocessor.transform(X_test)\n",
    "\n",
    "# Define models for stacking\n",
    "models_for_stacking = [\n",
    "    ('KNN', knn_model),\n",
    "    ('Logistic Regression', logreg_model),\n",
    "    ('Decision Tree', dt_model)\n",
    "]\n",
    "\n",
    "# Balancing Techniques\n",
    "balancing_methods = [\n",
    "    ('SMOTE', SMOTE(random_state=42)),\n",
    "    ('RandomUnderSampler', RandomUnderSampler(random_state=42)),\n",
    "    ('NearMiss', NearMiss(version=1, n_neighbors=3))\n",
    "]\n",
    "\n",
    "for method_name, balancing_method in balancing_methods:\n",
    "    print(f\"\\nPerformance after {method_name}:\")\n",
    "\n",
    "    # Clone the models for each balancing method\n",
    "    current_models_for_stacking = [(name, clone(model)) for name, model in models_for_stacking]\n",
    "\n",
    "    # Create the stacking model with the current balancing method\n",
    "    current_stacking_model = StackingClassifier(estimators=current_models_for_stacking, final_estimator=LogisticRegression(random_state=42))\n",
    "\n",
    "    # Apply balancing method to the training set\n",
    "    X_train_resampled, y_train_resampled = balancing_method.fit_resample(X_train_encoded, y_train)\n",
    "\n",
    "    # Fit the stacking model on the resampled data\n",
    "    current_stacking_model.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "    # Predictions on the test set after balancing\n",
    "    y_pred_resampled = current_stacking_model.predict(X_test_encoded)\n",
    "\n",
    "    # Evaluate the performance\n",
    "    print(f\"Accuracy ({method_name}):\", accuracy_score(y_test, y_pred_resampled))\n",
    "    print(f\"Classification Report ({method_name}):\\n\", classification_report(y_test, y_pred_resampled))\n",
    "    print(f\"Confusion Matrix ({method_name}):\\n\", confusion_matrix(y_test, y_pred_resampled))\n",
    "\n",
    "    # Calculate Cohen's Kappa\n",
    "    kappa_resampled = cohen_kappa_score(y_test, y_pred_resampled)\n",
    "    print(f\"Cohen's Kappa ({method_name}): {kappa_resampled}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb5b101-aec5-4644-b650-d24f869d0e84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfeafba8-a682-41cc-aae2-7931f17abcb1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
