{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5d18fa78-da7a-45a7-8f8b-dddec1be7141",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dba4d079-dba3-4d38-9520-d3a50fbb4f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data = pd.read_csv('../data/cleaned/combined_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3060a57e-8036-4b41-959f-45a48621fe53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (Unbalanced): 0.8309352517985612\n",
      "\n",
      "Classification Report (Unbalanced):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          No       0.84      0.98      0.90       226\n",
      "         Yes       0.67      0.19      0.30        52\n",
      "\n",
      "    accuracy                           0.83       278\n",
      "   macro avg       0.75      0.59      0.60       278\n",
      "weighted avg       0.81      0.83      0.79       278\n",
      "\n",
      "\n",
      "Confusion Matrix (Unbalanced):\n",
      " [[221   5]\n",
      " [ 42  10]]\n",
      "\n",
      "Performance after SMOTE:\n",
      "Accuracy (SMOTE): 0.7194244604316546\n",
      "Classification Report (SMOTE):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          No       0.86      0.78      0.82       226\n",
      "         Yes       0.32      0.44      0.37        52\n",
      "\n",
      "    accuracy                           0.72       278\n",
      "   macro avg       0.59      0.61      0.60       278\n",
      "weighted avg       0.76      0.72      0.74       278\n",
      "\n",
      "Confusion Matrix (SMOTE):\n",
      " [[177  49]\n",
      " [ 29  23]]\n",
      "Cohen's Kappa (SMOTE): 0.19641268900088937\n",
      "\n",
      "Performance after RandomUnderSampler:\n",
      "Accuracy (RandomUnderSampler): 0.7086330935251799\n",
      "Classification Report (RandomUnderSampler):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          No       0.83      0.80      0.82       226\n",
      "         Yes       0.26      0.31      0.28        52\n",
      "\n",
      "    accuracy                           0.71       278\n",
      "   macro avg       0.55      0.55      0.55       278\n",
      "weighted avg       0.73      0.71      0.72       278\n",
      "\n",
      "Confusion Matrix (RandomUnderSampler):\n",
      " [[181  45]\n",
      " [ 36  16]]\n",
      "Cohen's Kappa (RandomUnderSampler): 0.10179497407259674\n",
      "\n",
      "Performance after NearMiss:\n",
      "Accuracy (NearMiss): 0.7122302158273381\n",
      "Classification Report (NearMiss):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          No       0.83      0.81      0.82       226\n",
      "         Yes       0.27      0.31      0.29        52\n",
      "\n",
      "    accuracy                           0.71       278\n",
      "   macro avg       0.55      0.56      0.55       278\n",
      "weighted avg       0.73      0.71      0.72       278\n",
      "\n",
      "Confusion Matrix (NearMiss):\n",
      " [[182  44]\n",
      " [ 36  16]]\n",
      "Cohen's Kappa (NearMiss): 0.10668380462724936\n"
     ]
    }
   ],
   "source": [
    "# Separate features (X) and target variable (y)\n",
    "X = combined_data.drop('attrition', axis=1)\n",
    "y = combined_data['attrition']\n",
    "\n",
    "# Identify categorical columns to be encoded\n",
    "columns_to_encode = ['business_travel', 'department', 'education_field', 'gender', 'job_role', 'marital_status', 'over_time']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the transformer for categorical columns (OneHotEncoder)\n",
    "categorical_transformer = OneHotEncoder(drop='first')\n",
    "\n",
    "# Combine transformers using ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', categorical_transformer, columns_to_encode)\n",
    "    ])\n",
    "\n",
    "# Apply one-hot encoding to training and test sets\n",
    "X_train_encoded = preprocessor.fit_transform(X_train)\n",
    "X_test_encoded = preprocessor.transform(X_test)\n",
    "\n",
    "# Base KNN model\n",
    "knn_model = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# Combine preprocessing with a KNN model in a pipeline\n",
    "base_model = Pipeline(steps=[\n",
    "    ('classifier', knn_model)  \n",
    "])\n",
    "\n",
    "# Fit the base model on the training data\n",
    "base_model.fit(X_train_encoded, y_train)\n",
    "\n",
    "# Evaluate the performance of the base model\n",
    "print(\"Accuracy (Unbalanced):\", accuracy_score(y_test, base_model.predict(X_test_encoded)))\n",
    "print(\"\\nClassification Report (Unbalanced):\\n\", classification_report(y_test, base_model.predict(X_test_encoded)))\n",
    "print(\"\\nConfusion Matrix (Unbalanced):\\n\", confusion_matrix(y_test, base_model.predict(X_test_encoded)))\n",
    "\n",
    "# Balancing Techniques\n",
    "for method_name, balancing_method in balancing_methods:\n",
    "    print(f\"\\nPerformance after {method_name}:\")\n",
    "    \n",
    "    # Apply balancing method to the training set\n",
    "    X_train_resampled, y_train_resampled = balancing_method.fit_resample(X_train_encoded, y_train)\n",
    "\n",
    "    # Create a new instance of the KNN model\n",
    "    knn_model_resampled = KNeighborsClassifier(n_neighbors=5)\n",
    "    \n",
    "    # Combine preprocessing with the resampled KNN model in a pipeline\n",
    "    model_resampled = Pipeline(steps=[\n",
    "        ('classifier', knn_model_resampled)  \n",
    "    ])\n",
    "\n",
    "    # Fit the model on the resampled data\n",
    "    model_resampled.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "    # Evaluate the performance\n",
    "    print(f\"Accuracy ({method_name}):\", accuracy_score(y_test, model_resampled.predict(X_test_encoded)))\n",
    "    print(f\"Classification Report ({method_name}):\\n\", classification_report(y_test, model_resampled.predict(X_test_encoded)))\n",
    "    print(f\"Confusion Matrix ({method_name}):\\n\", confusion_matrix(y_test, model_resampled.predict(X_test_encoded)))\n",
    "\n",
    "    # Calculate Cohen's Kappa\n",
    "    kappa_resampled = cohen_kappa_score(y_test, model_resampled.predict(X_test_encoded))\n",
    "    print(f\"Cohen's Kappa ({method_name}): {kappa_resampled}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ca5aed-b09a-412d-a390-156741ffe5b6",
   "metadata": {},
   "source": [
    "### Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5ea5a81f-26c6-4c7a-949b-8871fed1ebc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Accuracy (Unbalanced): 0.8422159716277363\n",
      "\n",
      "Performance after SMOTE with cross-validation:\n",
      "Cross-Validation Accuracy (SMOTE): 0.7714736660036323\n",
      "\n",
      "Performance after RandomUnderSampler with cross-validation:\n",
      "Cross-Validation Accuracy (RandomUnderSampler): 0.6075653923541248\n",
      "\n",
      "Performance after NearMiss with cross-validation:\n",
      "Cross-Validation Accuracy (NearMiss): 0.5424547283702212\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "# Base KNN model\n",
    "knn_model = KNeighborsClassifier(n_neighbors=6)\n",
    "\n",
    "# Combine preprocessing with a KNN model in a pipeline\n",
    "base_model = Pipeline(steps=[\n",
    "    ('classifier', knn_model)  \n",
    "])\n",
    "\n",
    "# Perform cross-validation on the base model\n",
    "cv_scores_base = cross_val_score(base_model, X_train_encoded, y_train, cv=StratifiedKFold(n_splits=5), scoring='accuracy')\n",
    "\n",
    "# Evaluate the performance of the base model\n",
    "print(\"Cross-Validation Accuracy (Unbalanced):\", np.mean(cv_scores_base))\n",
    "\n",
    "# Balancing Techniques\n",
    "for method_name, balancing_method in balancing_methods:\n",
    "    print(f\"\\nPerformance after {method_name} with cross-validation:\")\n",
    "    \n",
    "    # Apply balancing method to the training set\n",
    "    X_train_resampled, y_train_resampled = balancing_method.fit_resample(X_train_encoded, y_train)\n",
    "\n",
    "    # Create a new instance of the KNN model\n",
    "    knn_model_resampled = KNeighborsClassifier(n_neighbors=6)\n",
    "    \n",
    "    # Combine preprocessing with the resampled KNN model in a pipeline\n",
    "    model_resampled = Pipeline(steps=[\n",
    "        ('classifier', knn_model_resampled)  \n",
    "    ])\n",
    "\n",
    "    # Perform cross-validation on the resampled model\n",
    "    cv_scores_resampled = cross_val_score(model_resampled, X_train_resampled, y_train_resampled, cv=StratifiedKFold(n_splits=5), scoring='accuracy')\n",
    "\n",
    "    # Evaluate the performance\n",
    "    print(f\"Cross-Validation Accuracy ({method_name}):\", np.mean(cv_scores_resampled))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ae14be-94d1-4a9b-805b-152cafb2db01",
   "metadata": {},
   "source": [
    "### Best parametr 'n_neighbors'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "39555dea-135a-40fd-8516-b8f2d20e30e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'n_neighbors': 6}\n",
      "Best Accuracy: 0.8485222779340426\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {'n_neighbors': range(1, 21)}  \n",
    "\n",
    "# Create the grid search object\n",
    "grid_search = GridSearchCV(knn_model, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "# Fit the grid search on the training data\n",
    "grid_search.fit(X_train_encoded, y_train)\n",
    "\n",
    "# Print the best parameters and corresponding accuracy\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best Accuracy:\", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc5d803b-f702-4370-8b14-72f2692f4b44",
   "metadata": {},
   "source": [
    "After running the model with suggested best parametr 'n_neighbors': 6, no improvements were noticed. Prediction for the class 'No' were even worse. So I dicided to keep the model with 'n_neighbors': 5, which showed the best metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d1a84b09-84f2-40a7-a0e1-f48b4b28c93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save model\n",
    "with open('../src/knn_model.pkl', 'wb') as file:\n",
    "    pickle.dump(base_model, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b6a3500-083a-4ae7-96c6-b7c6012de687",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
