{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d18fa78-da7a-45a7-8f8b-dddec1be7141",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dba4d079-dba3-4d38-9520-d3a50fbb4f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data = pd.read_csv('../data/cleaned/combined_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00d67369-77a9-4aa8-86ed-0b99f4a5c17c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8309352517985612\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          No       0.84      0.98      0.90       226\n",
      "         Yes       0.67      0.19      0.30        52\n",
      "\n",
      "    accuracy                           0.83       278\n",
      "   macro avg       0.75      0.59      0.60       278\n",
      "weighted avg       0.81      0.83      0.79       278\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " [[221   5]\n",
      " [ 42  10]]\n"
     ]
    }
   ],
   "source": [
    "X = combined_data.drop('attrition', axis=1)\n",
    "y = combined_data['attrition']\n",
    "\n",
    "# Identify categorical columns to be encoded\n",
    "columns_to_encode = ['business_travel', 'department', 'education_field', 'gender', 'job_role', 'marital_status', 'over_time']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the transformer for categorical columns (OneHotEncoder)\n",
    "categorical_transformer = OneHotEncoder(drop='first')\n",
    "\n",
    "# Combine transformers using ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', categorical_transformer, columns_to_encode),\n",
    "        # No numerical transformer for already scaled numerical columns\n",
    "    ])\n",
    "\n",
    "# Combine preprocessing with a KNN model in a pipeline\n",
    "model = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', KNeighborsClassifier(n_neighbors=5))  # You can adjust the number of neighbors (k) as needed\n",
    "])\n",
    "\n",
    "# Fit the model on the training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the performance\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98c45ab6-901a-4c90-bb74-687e50b9bcdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cohen's Kappa for KNN: 0.23438415563107928\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "# Calculate Cohen's Kappa for KNN model\n",
    "kappa_knn = cohen_kappa_score(y_test, y_pred)\n",
    "print(\"Cohen's Kappa for KNN:\", kappa_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "90727db5-e38b-40c9-9d58-6c7792565665",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (Unbalanced): 0.8309352517985612\n",
      "\n",
      "Classification Report (Unbalanced):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          No       0.84      0.98      0.90       226\n",
      "         Yes       0.67      0.19      0.30        52\n",
      "\n",
      "    accuracy                           0.83       278\n",
      "   macro avg       0.75      0.59      0.60       278\n",
      "weighted avg       0.81      0.83      0.79       278\n",
      "\n",
      "\n",
      "Confusion Matrix (Unbalanced):\n",
      " [[221   5]\n",
      " [ 42  10]]\n",
      "\n",
      "Performance after SMOTE:\n",
      "Accuracy (SMOTE): 0.7194244604316546\n",
      "Classification Report (SMOTE):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          No       0.86      0.78      0.82       226\n",
      "         Yes       0.32      0.44      0.37        52\n",
      "\n",
      "    accuracy                           0.72       278\n",
      "   macro avg       0.59      0.61      0.60       278\n",
      "weighted avg       0.76      0.72      0.74       278\n",
      "\n",
      "Confusion Matrix (SMOTE):\n",
      " [[177  49]\n",
      " [ 29  23]]\n",
      "Cohen's Kappa (SMOTE): 0.19641268900088937\n",
      "\n",
      "Performance after RandomUnderSampler:\n",
      "Accuracy (RandomUnderSampler): 0.7086330935251799\n",
      "Classification Report (RandomUnderSampler):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          No       0.83      0.80      0.82       226\n",
      "         Yes       0.26      0.31      0.28        52\n",
      "\n",
      "    accuracy                           0.71       278\n",
      "   macro avg       0.55      0.55      0.55       278\n",
      "weighted avg       0.73      0.71      0.72       278\n",
      "\n",
      "Confusion Matrix (RandomUnderSampler):\n",
      " [[181  45]\n",
      " [ 36  16]]\n",
      "Cohen's Kappa (RandomUnderSampler): 0.10179497407259674\n",
      "\n",
      "Performance after NearMiss:\n",
      "Accuracy (NearMiss): 0.7122302158273381\n",
      "Classification Report (NearMiss):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          No       0.83      0.81      0.82       226\n",
      "         Yes       0.27      0.31      0.29        52\n",
      "\n",
      "    accuracy                           0.71       278\n",
      "   macro avg       0.55      0.56      0.55       278\n",
      "weighted avg       0.73      0.71      0.72       278\n",
      "\n",
      "Confusion Matrix (NearMiss):\n",
      " [[182  44]\n",
      " [ 36  16]]\n",
      "Cohen's Kappa (NearMiss): 0.10668380462724936\n"
     ]
    }
   ],
   "source": [
    "# Separate features (X) and target variable (y)\n",
    "X = combined_data.drop('attrition', axis=1)\n",
    "y = combined_data['attrition']\n",
    "\n",
    "# Identify categorical columns to be encoded\n",
    "columns_to_encode = ['business_travel', 'department', 'education_field', 'gender', 'job_role', 'marital_status', 'over_time']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the transformer for categorical columns (OneHotEncoder)\n",
    "categorical_transformer = OneHotEncoder(drop='first')\n",
    "\n",
    "# Combine transformers using ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', categorical_transformer, columns_to_encode)\n",
    "    ])\n",
    "\n",
    "# Apply one-hot encoding to training and test sets\n",
    "X_train_encoded = preprocessor.fit_transform(X_train)\n",
    "X_test_encoded = preprocessor.transform(X_test)\n",
    "\n",
    "# Combine preprocessing with a KNN model in a pipeline\n",
    "model = Pipeline(steps=[\n",
    "    ('classifier', KNeighborsClassifier(n_neighbors=5))  # You can adjust the number of neighbors (k) as needed\n",
    "])\n",
    "\n",
    "# Fit the model on the training data\n",
    "model.fit(X_train_encoded, y_train)\n",
    "\n",
    "# Predictions on the test set\n",
    "y_pred = model.predict(X_test_encoded)\n",
    "\n",
    "# Evaluate the performance\n",
    "print(\"Accuracy (Unbalanced):\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report (Unbalanced):\\n\", classification_report(y_test, y_pred))\n",
    "print(\"\\nConfusion Matrix (Unbalanced):\\n\", confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Balancing Techniques\n",
    "balancing_methods = [\n",
    "    ('SMOTE', SMOTE(random_state=42)),\n",
    "    ('RandomUnderSampler', RandomUnderSampler(random_state=42)),\n",
    "    ('NearMiss', NearMiss(version=1, n_neighbors=3))\n",
    "]\n",
    "\n",
    "for method_name, balancing_method in balancing_methods:\n",
    "    print(f\"\\nPerformance after {method_name}:\")\n",
    "    \n",
    "    # Apply balancing method to the training set\n",
    "    X_train_resampled, y_train_resampled = balancing_method.fit_resample(X_train_encoded, y_train)\n",
    "\n",
    "    # Fit the model on the resampled data\n",
    "    model.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "    # Predictions on the test set after balancing\n",
    "    y_pred_resampled = model.predict(X_test_encoded)\n",
    "\n",
    "    # Evaluate the performance\n",
    "    print(f\"Accuracy ({method_name}):\", accuracy_score(y_test, y_pred_resampled))\n",
    "    print(f\"Classification Report ({method_name}):\\n\", classification_report(y_test, y_pred_resampled))\n",
    "    print(f\"Confusion Matrix ({method_name}):\\n\", confusion_matrix(y_test, y_pred_resampled))\n",
    "\n",
    "    # Calculate Cohen's Kappa\n",
    "    kappa_resampled = cohen_kappa_score(y_test, y_pred_resampled)\n",
    "    print(f\"Cohen's Kappa ({method_name}): {kappa_resampled}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d1a84b09-84f2-40a7-a0e1-f48b4b28c93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save model\n",
    "with open('../src/knn_model.pkl', 'wb') as file:\n",
    "    pickle.dump(model, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17db3b18-6601-4b41-97eb-0b9dbbc19b6a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
